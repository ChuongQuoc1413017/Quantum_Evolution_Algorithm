{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"\"\n",
    "train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
    "                       delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = 1.0 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac\n",
    "\n",
    "\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from Qsun.Qcircuit import *\n",
    "from Qsun.Qgates import *\n",
    "from Qsun.Qmeas import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from itertools import permutations\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one layer with full entanglement\n",
    "def layer(circuit, params, engtangled):\n",
    "    circuit_layer = circuit\n",
    "    n_qubit = len(params)\n",
    "    for i in range(n_qubit):\n",
    "        RX(circuit_layer, i, params[i][0])\n",
    "        RY(circuit_layer, i, params[i][1])\n",
    "    if n_qubit > 1:\n",
    "        if engtangled == 'circle':\n",
    "            for i in range(n_qubit-1):\n",
    "                CNOT(circuit_layer, i, i+1)\n",
    "            CNOT(circuit_layer, n_qubit-1, 0)\n",
    "        elif engtangled == 'full':\n",
    "            permutation_list = list(permutations(range(n_qubit), 2))\n",
    "            for i in permutation_list:\n",
    "                CNOT(circuit_layer, i[0], i[1])\n",
    "        elif engtangled == 'pair':\n",
    "            for j in range(int(n_qubit/2)):\n",
    "                for i in range(j, n_qubit-j-1, 2):\n",
    "                    CNOT(circuit_layer, i, i+1)\n",
    "    return circuit_layer\n",
    "\n",
    "# amplitude encoding the features\n",
    "def initial_state_amplitude(sample):\n",
    "    qubit_num = int(math.ceil(np.log2(len(sample))))\n",
    "    circuit_initial = Qubit(qubit_num)\n",
    "    circuit_initial.amplitude[0:len(sample)] = sample/np.sqrt(np.sum(sample**2))\n",
    "    return circuit_initial\n",
    "\n",
    "# qubit encoding the features\n",
    "def initial_state_qubit(sample):\n",
    "    circuit_initial = Qubit(len(sample))\n",
    "    ampli_vec = np.array([np.cos(sample[0]/2), np.sin(sample[0]/2)])\n",
    "    for i in range(1, len(sample)):\n",
    "        ampli_vec = np.kron(ampli_vec, np.array([np.cos(sample[i]/2), np.sin(sample[i]/2)]))\n",
    "    circuit_initial.amplitude = ampli_vec\n",
    "    return circuit_initial\n",
    "\n",
    "# dense qubit encoding the features\n",
    "def initial_state_dense(sample):\n",
    "    qubit_num = int(len(sample)/2)\n",
    "    circuit_initial = Qubit(qubit_num)\n",
    "    ampli_vec = np.array([np.cos(sample[0+qubit_num]/2)*np.cos(sample[0]/2) + 1j*np.sin(sample[0+qubit_num]/2)*np.sin(sample[0]/2),\n",
    "                          np.sin(sample[0+qubit_num]/2)*np.cos(sample[0]/2) - 1j*np.cos(sample[0+qubit_num]/2)*np.sin(sample[0]/2)])\n",
    "    for i in range(1, qubit_num):\n",
    "        ampli_vec = np.kron(ampli_vec, np.array([np.cos(sample[i+qubit_num]/2)*np.cos(sample[i]/2) + 1j*np.sin(sample[i+qubit_num]/2)*np.sin(sample[i]/2),\n",
    "                                       np.sin(sample[i+qubit_num]/2)*np.cos(sample[i]/2) - 1j*np.cos(sample[i+qubit_num]/2)*np.sin(sample[i]/2)]))\n",
    "    circuit_initial.amplitude = ampli_vec\n",
    "    return circuit_initial\n",
    "\n",
    "# QNN circuit\n",
    "def qnn(circuit, params, engtangled):\n",
    "    n_layer = len(params)\n",
    "    circuit_qnn = circuit\n",
    "    for i in range(n_layer):\n",
    "        circuit_qnn = layer(circuit_qnn, params[i], engtangled)\n",
    "    return circuit_qnn\n",
    "\n",
    "# QNN model\n",
    "def qnn_model(sample, params, encoded, engtangled):\n",
    "    if encoded == 'amplitude':\n",
    "        circuit_model = initial_state_amplitude(sample)\n",
    "    elif encoded == 'qubit':\n",
    "        circuit_model = initial_state_qubit(sample)\n",
    "    elif encoded == 'dense':\n",
    "        circuit_model = initial_state_dense(sample)\n",
    "    circuit_model = qnn(circuit_model, params, engtangled)\n",
    "    return circuit_model\n",
    "\n",
    "# activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "# make a prediction\n",
    "def predict(circuit, activation):\n",
    "    probs = 2*predict_exp(circuit)-1\n",
    "    if activation == 'sigmoid':\n",
    "        return sigmoid(probs)\n",
    "    elif activation == 'tanh':\n",
    "        return tanh(probs)\n",
    "    elif activation == 'relu':\n",
    "        return relu(probs)\n",
    "    else:\n",
    "        return (probs - 1) / 2\n",
    "\n",
    "# make a prediction for expectation\n",
    "def predict_exp(circuit):\n",
    "    num_qubit = int(np.log2(len(circuit.state)))\n",
    "    expval = np.array([measure_one(circuit, i)[1] for i in range(num_qubit)])\n",
    "    return expval\n",
    "\n",
    "# loss function    \n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (1 - p[l]) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "# loss function of QNN\n",
    "def cost(params, features, labels):\n",
    "    preds = np.array([predict(qnn_model(x, params, encoded='amplitude', engtangled='circle'), activation='sigmoid') for x in features])\n",
    "#     return square_loss(labels, preds)\n",
    "#     preds = np.argmax(preds, axis=1)\n",
    "#     return accuracy_score(labels, preds)\n",
    "    labels = to_categorical(labels)\n",
    "    return roc_auc_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(pop_size, n_genes, input_limits):\n",
    "\n",
    "    population = np.random.uniform(\n",
    "      input_limits[0], input_limits[1], size=(pop_size, n_genes)\n",
    "    )\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(individual):\n",
    "    \n",
    "    params = np.resize(individual, (4, int(math.ceil(np.log2(16))), 2))\n",
    "#     return -cost(params, X_train, y_train)\n",
    "    return cost(params, X_train, y_train)\n",
    "\n",
    "def calculate_fitness(population):\n",
    "    \n",
    "    return np.array([fitness_function(individual) for individual in population])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(selection_strategy, n_matings, fitness, prob_intervals):\n",
    "    \"\"\"\n",
    "    Selects the parents according to a given selection strategy.\n",
    "    Options are:\n",
    "    roulette_wheel: Selects individuals from mating pool giving\n",
    "    higher probabilities to fitter individuals.\n",
    "    \n",
    "    :param selection_strategy: the strategy to use for selecting parents\n",
    "    :param n_matings: the number of matings to perform\n",
    "    :param prob_intervals: the selection probability for each individual in \n",
    "     the mating pool.\n",
    "    :return: 2 arrays with selected individuals corresponding to each parent\n",
    "    \"\"\"\n",
    "\n",
    "    ma, pa = None, None\n",
    "\n",
    "    if selection_strategy == \"roulette_wheel\":\n",
    "\n",
    "        ma = np.apply_along_axis(\n",
    "            lambda value: np.argmin(value > prob_intervals) - 1, 1, np.random.rand(n_matings, 1)\n",
    "        )\n",
    "        pa = np.apply_along_axis(\n",
    "            lambda value: np.argmin(value > prob_intervals) - 1, 1, np.random.rand(n_matings, 1)\n",
    "        )\n",
    "        \n",
    "    return ma, pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_offspring(first_parent, sec_parent, crossover_pt, offspring_number):\n",
    "\n",
    "    beta = (np.random.rand(1)[0] if offspring_number == \"first\" else -np.random.rand(1)[0])\n",
    "\n",
    "    p_new = first_parent[crossover_pt] - beta * (first_parent[crossover_pt] - sec_parent[crossover_pt])\n",
    "\n",
    "    return np.hstack((first_parent[:crossover_pt], p_new, sec_parent[crossover_pt + 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_population(population, n_mutations, input_limits):\n",
    "\n",
    "    mutation_rows = np.random.choice(np.arange(1, population.shape[0]), n_mutations, replace=True)\n",
    "    mutation_columns = np.random.choice(population.shape[1], n_mutations, replace=True)\n",
    "    \n",
    "    new_population = np.random.uniform(input_limits[0], input_limits[1], size=population.shape)\n",
    "\n",
    "    population[mutation_rows, mutation_columns] = new_population[mutation_rows, mutation_columns]\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_fitness(fitness, population):\n",
    "\n",
    "    sorted_fitness = np.argsort(fitness)[::-1]\n",
    "\n",
    "    population = population[sorted_fitness, :]\n",
    "    fitness = fitness[sorted_fitness]\n",
    "\n",
    "    return fitness, population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selection_probabilities(selection_strategy, pop_keep):\n",
    "\n",
    "    if selection_strategy == \"roulette_wheel\":\n",
    "        mating_prob = (np.arange(1, pop_keep + 1) / np.arange(1, pop_keep + 1).sum())[::-1]\n",
    "        return np.array([0, *np.cumsum(mating_prob[: pop_keep + 1])])\n",
    "    \n",
    "    elif selection_strategy == \"random\":\n",
    "        return np.linspace(0, 1, pop_keep + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = train_labels.flatten()\n",
    "X_test = []\n",
    "y_test = test_labels.flatten()\n",
    "\n",
    "for i in range(len(train_imgs)):\n",
    "    X_train.append((cv2.resize(train_imgs[i].reshape((28,28)), (4, 4), interpolation = cv2.INTER_AREA)).flatten())\n",
    "    \n",
    "for i in range(len(test_imgs)):\n",
    "    X_test.append((cv2.resize(test_imgs[i].reshape((28,28)), (4, 4), interpolation = cv2.INTER_AREA)).flatten())\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_01 = X_train[(y_train==3) | (y_train==6)]\n",
    "# X_test_01 = X_test[(y_test==3) | (y_test==6)]\n",
    "\n",
    "# y_train_01 = y_train[(y_train==3) | (y_train==6)]\n",
    "# y_test_01 = y_test[(y_test==3) | (y_test==6)]\n",
    "\n",
    "# y_train_01 = (y_train_01/3-1).astype('int32')\n",
    "# y_test_01 = (y_test_01/3-1).astype('int32')\n",
    "\n",
    "X_train_01 = X_train[y_train<4]\n",
    "X_test_01 = X_test[y_test<4]\n",
    "\n",
    "y_train_01 = y_train[y_train<4]\n",
    "y_test_01 = y_test[y_test<4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_01, y_train_01, \n",
    "                                                    test_size=(len(y_train_01)-n_samples)/len(y_train_01), \n",
    "                                                    stratify=y_train_01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_strategy = \"roulette_wheel\" \n",
    "selection_rate = 0.5\n",
    "mutation_rate = 0.1\n",
    "\n",
    "n_genes = 32 # number of variables\n",
    "pop_size = 80 # population size\n",
    "pop_keep = math.floor(selection_rate * pop_size) # number of individuals to keep on each iteration\n",
    "\n",
    "n_matings = math.floor((pop_size - pop_keep) / 2) # number of crossovers to perform\n",
    "n_mutations = math.ceil((pop_size - 1) * n_genes * mutation_rate) # number o mutations to perform\n",
    "\n",
    "# probability intervals, needed for roulete_wheel and random selection strategies\n",
    "prob_intervals = get_selection_probabilities(selection_strategy, pop_keep)\n",
    "\n",
    "max_gen = 20 # Maximum number of generations\n",
    "input_limits = (0, np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = initialize_population(pop_size, n_genes, input_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# calculate_fitness(population)\n",
    "# time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7035.24795293808"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the population\n",
    "population = initialize_population(pop_size, n_genes, input_limits)\n",
    "\n",
    "# Calculate the fitness of the population\n",
    "fitness = calculate_fitness(population)\n",
    "\n",
    "# Sort population by fitness\n",
    "fitness, population = sort_by_fitness(fitness, population)\n",
    "\n",
    "gen_n = 0\n",
    "start = time.time()\n",
    "while True:\n",
    "\n",
    "    gen_n += 1\n",
    "\n",
    "    # Get parents pairs\n",
    "    ma, pa = select_parents(selection_strategy, n_matings, fitness, prob_intervals)\n",
    "\n",
    "    # Get indices of individuals to be replaced\n",
    "    ix = np.arange(0, pop_size - pop_keep - 1, 2)\n",
    "\n",
    "    # Get crossover point for each individual\n",
    "    xp = np.random.randint(0, n_genes, size=(len(ix), 1))\n",
    "\n",
    "    for i in range(len(ix)):\n",
    "\n",
    "        # create first offspring\n",
    "        population[-1 - ix[i], :] = create_offspring(population[ma[i], :], population[pa[i], :], xp[i][0], \"first\")\n",
    "\n",
    "        # create second offspring\n",
    "        population[-1 - ix[i] - 1, :] = create_offspring(population[pa[i], :], population[ma[i], :], xp[i][0], \"second\")\n",
    "\n",
    "    population = mutate_population(population, n_mutations, input_limits)\n",
    "\n",
    "    # Get new population's fitness. Since the fittest element does not change,\n",
    "    # we do not need to re calculate its fitness\n",
    "    fitness = np.hstack((fitness[0], calculate_fitness(population[1:, :])))\n",
    "\n",
    "    fitness, population = sort_by_fitness(fitness, population)\n",
    "\n",
    "    if gen_n >= max_gen:\n",
    "        break\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.13610122, 2.22121173, 0.40669703, ..., 0.15814969, 1.21086903,\n",
       "        2.87757263],\n",
       "       [1.87284352, 2.10935972, 1.0394203 , ..., 1.62538125, 3.11664121,\n",
       "        1.01436873],\n",
       "       [1.87284352, 2.10935972, 1.0394203 , ..., 0.99708572, 3.11664121,\n",
       "        1.01436873],\n",
       "       ...,\n",
       "       [0.64894618, 0.32898689, 1.82616318, ..., 0.15814969, 1.21086903,\n",
       "        2.87757263],\n",
       "       [2.16417572, 2.53166255, 0.93029596, ..., 1.62538125, 3.11664121,\n",
       "        1.01436873],\n",
       "       [0.33236456, 0.55448638, 1.44983272, ..., 0.34841568, 0.35009966,\n",
       "        1.28743955]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81359128, 0.74970238, 0.73259501, 0.72976075, 0.72460176,\n",
       "       0.71441764, 0.71033528, 0.71030215, 0.708594  , 0.70457152,\n",
       "       0.70300288, 0.68906541, 0.66512363, 0.66346661, 0.66088863,\n",
       "       0.65879841, 0.64961594, 0.64670958, 0.64156   , 0.62928466,\n",
       "       0.627359  , 0.62662985, 0.62466399, 0.61530202, 0.60995643,\n",
       "       0.60991506, 0.60858228, 0.58843401, 0.58757006, 0.58179921,\n",
       "       0.57127572, 0.5676694 , 0.56648593, 0.56575245, 0.56535548,\n",
       "       0.56318249, 0.56290959, 0.56274983, 0.5608092 , 0.56064724,\n",
       "       0.56013427, 0.55714987, 0.55094797, 0.54677354, 0.54391294,\n",
       "       0.54272583, 0.53706994, 0.53011927, 0.52508451, 0.52503146,\n",
       "       0.52501155, 0.52423472, 0.52389066, 0.52278151, 0.51458054,\n",
       "       0.50624976, 0.50205369, 0.48911127, 0.4890671 , 0.48514954,\n",
       "       0.48422189, 0.48288253, 0.48226494, 0.47847031, 0.47561546,\n",
       "       0.4705324 , 0.46745809, 0.46160555, 0.44215201, 0.44072975,\n",
       "       0.43554174, 0.43109684, 0.42346964, 0.41654072, 0.39530626,\n",
       "       0.37944523, 0.37229778, 0.37017563, 0.35727751, 0.34010984])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13610122, 2.22121173, 0.40669703, 1.71764523, 2.16593435,\n",
       "       1.48325144, 1.08647388, 1.44247405, 0.44436745, 2.8341956 ,\n",
       "       1.9430751 , 2.6300716 , 2.69227284, 1.41449973, 1.16330719,\n",
       "       2.51550296, 0.59673017, 1.67985961, 1.5769087 , 1.00873614,\n",
       "       2.09557385, 2.30564705, 1.9211751 , 1.01402379, 0.63885793,\n",
       "       1.19281985, 0.42759409, 1.07589569, 2.98110291, 0.15814969,\n",
       "       1.21086903, 2.87757263])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135912834568597"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49314409429877315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.resize(population[0], (4, int(math.ceil(np.log2(16))), 2))\n",
    "pred = [predict(qnn_model(x, params, encoded='amplitude', engtangled='circle'), activation='sigmoid') for x in X_test_01]\n",
    "pred = np.argmax(pred, axis=1)\n",
    "accuracy_score(y_test_01, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.resize(population[0], (4, int(math.ceil(np.log2(16))), 2))\n",
    "pred = [predict(qnn_model(x, params, encoded='amplitude', engtangled='circle'), activation='sigmoid') for x in X_train]\n",
    "pred = np.argmax(pred, axis=1)\n",
    "accuracy_score(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48448624417684805"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.resize(population[0], (4, int(math.ceil(np.log2(16))), 2))\n",
    "pred = [predict(qnn_model(x, params, encoded='amplitude', engtangled='circle'), activation='sigmoid') for x in X_test]\n",
    "pred = np.argmax(pred, axis=1)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
